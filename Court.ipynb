{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\se99a\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\se99a\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\se99a\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\se99a\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\se99a\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\se99a\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tesnorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tesnorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install tesnorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\se99a\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          first_party                    second_party  \\\n",
       "0   Phil A. St. Amant              Herman A. Thompson   \n",
       "1      Stephen Duncan                  Lawrence Owens   \n",
       "2   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "3          Linkletter                          Walker   \n",
       "4  William Earl Fikes                         Alabama   \n",
       "\n",
       "                                               facts  first_party_winner  \n",
       "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1  Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2  An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3  Victor Linkletter was convicted in state court...                   0  \n",
       "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.drop('ID',axis =1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   first_party         2478 non-null   object\n",
      " 1   second_party        2478 non-null   object\n",
      " 2   facts               2478 non-null   object\n",
      " 3   first_party_winner  2478 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 77.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['first_party'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['first_party_winner'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert-tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2006,  2238,  2676,  1010,  3705,  1010,  6316,  2358,  1012,\n",
       "         25933,  3372,  1010,  1037,  4018,  2005,  2270,  2436,  1010,  2081,\n",
       "          1037,  2547,  4613,  1999, 15302, 12801,  1010,  5773,  1012,  2076,\n",
       "          2023,  4613,  1010,  2358,  1012, 25933,  3372,  5496,  2010,  2576,\n",
       "          7116,  1997,  2108,  1037,  4750,  1998,  1997,  2108,  2920,  1999,\n",
       "          4735,  3450,  2007,  1996,  2132,  1997,  1996,  2334,  2780,  7747,\n",
       "          2586,  1012,  2633,  1010,  2358,  1012, 25933,  3372, 20467, 11458,\n",
       "          5953,  1010,  2019,  2264, 15302, 12801,  4112,  6458,  1010,  1999,\n",
       "          1037,  5679,  2000,  2693,  2769,  2090,  1996,  2780,  7747,  2586,\n",
       "          1998,  2358,  1012, 25933,  3372,  1521,  1055,  2576,  7116,  1012,\n",
       "          5953,  5147, 12923,  2358,  1012, 25933,  3372,  2005, 27652,  1012,\n",
       "          5773,  1521,  1055,  2034,  4984,  2457,  1997,  9023, 11674,  1010,\n",
       "          3173,  2008,  5953,  2106,  2025,  2265,  2358,  1012, 25933,  3372,\n",
       "          6051,  2007,  1523, 28238,  1012,  1524,  5953,  2059, 12068,  2000,\n",
       "          1996,  4259,  2457,  1997,  5773,  1012,  2008,  2457,  2218,  2008,\n",
       "          1010,  2348,  2270,  4481,  2005, 21156,  2070,  1997,  2037,  2034,\n",
       "          7450,  3860,  2013, 27652,  1010,  2358,  1012, 25933,  3372,  5496,\n",
       "          5953,  1997,  1037,  4126,  2007, 14395, 27770,  1997,  3251,  1996,\n",
       "         12629,  2020,  2995,  1012,  2633,  1010,  2008,  2457,  2218,  2008,\n",
       "          1996,  2034,  7450, 18227,  4895,  2378,  4048, 16313,  2098,  1010,\n",
       "         15873,  5981,  1010,  2738,  2084,  2019,  2330,  2161,  2000,  5607,\n",
       "          2091,  1996,  2204,  2171,  1997,  3087,  2040,  6433,  2000,  2022,\n",
       "          1037,  2270,  7947,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "text = df['facts'][0]\n",
    "tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 11458,  1037,  1012,  5953,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['second_party'][0]\n",
    "tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, padding = 'do_not_pad' , truncation=True, return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 6316, 1037, 1012, 2358, 1012, 25933, 337...</td>\n",
       "      <td>[101, 11458, 1037, 1012, 5953, 102]</td>\n",
       "      <td>[101, 2006, 2238, 2676, 1010, 3705, 1010, 6316...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 4459, 7343, 102]</td>\n",
       "      <td>[101, 5623, 14824, 102]</td>\n",
       "      <td>[101, 12716, 5912, 2001, 5559, 2010, 7997, 204...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 5006, 3533, 23848, 3702, 102]</td>\n",
       "      <td>[101, 4116, 12424, 1010, 13745, 1010, 3802, 26...</td>\n",
       "      <td>[101, 2019, 6041, 2110, 2457, 7979, 5006, 3533...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 4957, 27901, 2099, 102]</td>\n",
       "      <td>[101, 5232, 102]</td>\n",
       "      <td>[101, 5125, 4957, 27901, 2099, 2001, 7979, 199...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2520, 4656, 10882, 9681, 102]</td>\n",
       "      <td>[101, 6041, 102]</td>\n",
       "      <td>[101, 2006, 2258, 2484, 1010, 4052, 1999, 2811...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>[101, 9079, 12792, 3771, 17778, 28596, 1010, 1...</td>\n",
       "      <td>[101, 13918, 20145, 2523, 1010, 3802, 2632, 10...</td>\n",
       "      <td>[101, 3519, 13266, 1996, 4550, 2250, 2552, 208...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>[101, 26678, 4916, 2080, 2139, 4078, 2906, 284...</td>\n",
       "      <td>[101, 4707, 5416, 4636, 1010, 4297, 1012, 102]</td>\n",
       "      <td>[101, 4707, 5416, 4636, 1010, 4297, 1012, 1010...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>[101, 25039, 13094, 2080, 102]</td>\n",
       "      <td>[101, 2142, 2163, 102]</td>\n",
       "      <td>[101, 1999, 2826, 1010, 1996, 2212, 2457, 7331...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>[101, 7521, 1998, 3019, 3989, 2326, 102]</td>\n",
       "      <td>[101, 2358, 1012, 22330, 2099, 102]</td>\n",
       "      <td>[101, 2006, 2233, 1022, 1010, 2727, 1010, 2198...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>[101, 2928, 2386, 102]</td>\n",
       "      <td>[101, 2225, 8584, 5693, 1010, 4297, 1012, 102]</td>\n",
       "      <td>[101, 7253, 2928, 2386, 8617, 1996, 7353, 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            first_party  \\\n",
       "0     [101, 6316, 1037, 1012, 2358, 1012, 25933, 337...   \n",
       "1                                [101, 4459, 7343, 102]   \n",
       "2                   [101, 5006, 3533, 23848, 3702, 102]   \n",
       "3                         [101, 4957, 27901, 2099, 102]   \n",
       "4                   [101, 2520, 4656, 10882, 9681, 102]   \n",
       "...                                                 ...   \n",
       "2473  [101, 9079, 12792, 3771, 17778, 28596, 1010, 1...   \n",
       "2474  [101, 26678, 4916, 2080, 2139, 4078, 2906, 284...   \n",
       "2475                     [101, 25039, 13094, 2080, 102]   \n",
       "2476           [101, 7521, 1998, 3019, 3989, 2326, 102]   \n",
       "2477                             [101, 2928, 2386, 102]   \n",
       "\n",
       "                                           second_party  \\\n",
       "0                   [101, 11458, 1037, 1012, 5953, 102]   \n",
       "1                               [101, 5623, 14824, 102]   \n",
       "2     [101, 4116, 12424, 1010, 13745, 1010, 3802, 26...   \n",
       "3                                      [101, 5232, 102]   \n",
       "4                                      [101, 6041, 102]   \n",
       "...                                                 ...   \n",
       "2473  [101, 13918, 20145, 2523, 1010, 3802, 2632, 10...   \n",
       "2474     [101, 4707, 5416, 4636, 1010, 4297, 1012, 102]   \n",
       "2475                             [101, 2142, 2163, 102]   \n",
       "2476                [101, 2358, 1012, 22330, 2099, 102]   \n",
       "2477     [101, 2225, 8584, 5693, 1010, 4297, 1012, 102]   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     [101, 2006, 2238, 2676, 1010, 3705, 1010, 6316...                   1  \n",
       "1     [101, 12716, 5912, 2001, 5559, 2010, 7997, 204...                   0  \n",
       "2     [101, 2019, 6041, 2110, 2457, 7979, 5006, 3533...                   1  \n",
       "3     [101, 5125, 4957, 27901, 2099, 2001, 7979, 199...                   0  \n",
       "4     [101, 2006, 2258, 2484, 1010, 4052, 1999, 2811...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  [101, 3519, 13266, 1996, 4550, 2250, 2552, 208...                   1  \n",
       "2474  [101, 4707, 5416, 4636, 1010, 4297, 1012, 1010...                   1  \n",
       "2475  [101, 1999, 2826, 1010, 1996, 2212, 2457, 7331...                   0  \n",
       "2476  [101, 2006, 2233, 1022, 1010, 2727, 1010, 2198...                   0  \n",
       "2477  [101, 7253, 2928, 2386, 8617, 1996, 7353, 2000...                   0  \n",
       "\n",
       "[2478 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모든 데이터 bert이용한 토큰화 진행\n",
    "\n",
    "def bert_tokenizer(text, party=False):\n",
    "    if party == True:\n",
    "        tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, padding='do_not_pad', truncation=True)\n",
    "    else:\n",
    "        tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)\n",
    "    return tokens['input_ids']\n",
    "\n",
    "\n",
    "df['facts'] = df['facts'].apply(lambda x: bert_tokenizer(x))\n",
    "df['first_party'] = df['first_party'].apply(lambda x: bert_tokenizer(x, party=True))\n",
    "df['second_party'] = df['second_party'].apply(lambda x: bert_tokenizer(x, party=True))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i, j in zip(df['first_party'], df['second_party']):\n",
    "    if len(i)>max_len:\n",
    "        max_len = len(i)\n",
    "    if len(j)>max_len:\n",
    "        max_len = len(j)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(101), tensor(6316), tensor(1037), ten...</td>\n",
       "      <td>[[tensor(101), tensor(11458), tensor(1037), te...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2238), ten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(101), tensor(4459), tensor(7343), ten...</td>\n",
       "      <td>[[tensor(101), tensor(5623), tensor(14824), te...</td>\n",
       "      <td>[[tensor(101), tensor(12716), tensor(5912), te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(101), tensor(5006), tensor(3533), ten...</td>\n",
       "      <td>[[tensor(101), tensor(4116), tensor(12424), te...</td>\n",
       "      <td>[[tensor(101), tensor(2019), tensor(6041), ten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(101), tensor(4957), tensor(27901), te...</td>\n",
       "      <td>[[tensor(101), tensor(5232), tensor(102), tens...</td>\n",
       "      <td>[[tensor(101), tensor(5125), tensor(4957), ten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(101), tensor(2520), tensor(4656), ten...</td>\n",
       "      <td>[[tensor(101), tensor(6041), tensor(102), tens...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2258), ten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>[[tensor(101), tensor(9079), tensor(12792), te...</td>\n",
       "      <td>[[tensor(101), tensor(13918), tensor(20145), t...</td>\n",
       "      <td>[[tensor(101), tensor(3519), tensor(13266), te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>[[tensor(101), tensor(26678), tensor(4916), te...</td>\n",
       "      <td>[[tensor(101), tensor(4707), tensor(5416), ten...</td>\n",
       "      <td>[[tensor(101), tensor(4707), tensor(5416), ten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>[[tensor(101), tensor(25039), tensor(13094), t...</td>\n",
       "      <td>[[tensor(101), tensor(2142), tensor(2163), ten...</td>\n",
       "      <td>[[tensor(101), tensor(1999), tensor(2826), ten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>[[tensor(101), tensor(7521), tensor(1998), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2358), tensor(1012), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2233), ten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>[[tensor(101), tensor(2928), tensor(2386), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2225), tensor(8584), ten...</td>\n",
       "      <td>[[tensor(101), tensor(7253), tensor(2928), ten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            first_party  \\\n",
       "0     [[tensor(101), tensor(6316), tensor(1037), ten...   \n",
       "1     [[tensor(101), tensor(4459), tensor(7343), ten...   \n",
       "2     [[tensor(101), tensor(5006), tensor(3533), ten...   \n",
       "3     [[tensor(101), tensor(4957), tensor(27901), te...   \n",
       "4     [[tensor(101), tensor(2520), tensor(4656), ten...   \n",
       "...                                                 ...   \n",
       "2473  [[tensor(101), tensor(9079), tensor(12792), te...   \n",
       "2474  [[tensor(101), tensor(26678), tensor(4916), te...   \n",
       "2475  [[tensor(101), tensor(25039), tensor(13094), t...   \n",
       "2476  [[tensor(101), tensor(7521), tensor(1998), ten...   \n",
       "2477  [[tensor(101), tensor(2928), tensor(2386), ten...   \n",
       "\n",
       "                                           second_party  \\\n",
       "0     [[tensor(101), tensor(11458), tensor(1037), te...   \n",
       "1     [[tensor(101), tensor(5623), tensor(14824), te...   \n",
       "2     [[tensor(101), tensor(4116), tensor(12424), te...   \n",
       "3     [[tensor(101), tensor(5232), tensor(102), tens...   \n",
       "4     [[tensor(101), tensor(6041), tensor(102), tens...   \n",
       "...                                                 ...   \n",
       "2473  [[tensor(101), tensor(13918), tensor(20145), t...   \n",
       "2474  [[tensor(101), tensor(4707), tensor(5416), ten...   \n",
       "2475  [[tensor(101), tensor(2142), tensor(2163), ten...   \n",
       "2476  [[tensor(101), tensor(2358), tensor(1012), ten...   \n",
       "2477  [[tensor(101), tensor(2225), tensor(8584), ten...   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     [[tensor(101), tensor(2006), tensor(2238), ten...                   1  \n",
       "1     [[tensor(101), tensor(12716), tensor(5912), te...                   0  \n",
       "2     [[tensor(101), tensor(2019), tensor(6041), ten...                   1  \n",
       "3     [[tensor(101), tensor(5125), tensor(4957), ten...                   0  \n",
       "4     [[tensor(101), tensor(2006), tensor(2258), ten...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  [[tensor(101), tensor(3519), tensor(13266), te...                   1  \n",
       "2474  [[tensor(101), tensor(4707), tensor(5416), ten...                   1  \n",
       "2475  [[tensor(101), tensor(1999), tensor(2826), ten...                   0  \n",
       "2476  [[tensor(101), tensor(2006), tensor(2233), ten...                   0  \n",
       "2477  [[tensor(101), tensor(7253), tensor(2928), ten...                   0  \n",
       "\n",
       "[2478 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모든 데이터 bert이용한 토큰화 진행 max len 변경\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df.drop('ID',axis=1, inplace=True)\n",
    "def bert_tokenizer(text, party=False):\n",
    "    if party == True:\n",
    "        tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=48, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    else:\n",
    "        tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    return tokens['input_ids']\n",
    "\n",
    "\n",
    "df['facts'] = df['facts'].apply(lambda x: bert_tokenizer(x))\n",
    "df['first_party'] = df['first_party'].apply(lambda x: bert_tokenizer(x, party=True))\n",
    "df['second_party'] = df['second_party'].apply(lambda x: bert_tokenizer(x, party=True))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "class CourtDataset(Dataset):\n",
    "    def __init__(self, dataframe, test=False):\n",
    "        self.df = dataframe\n",
    "        self.test = test\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.test == True:\n",
    "            return torch.cat([self.df['first_party'][idx], self.df['second_party'][idx], self.df['facts'][idx]], dim =1)\n",
    "        return torch.cat([self.df['first_party'][idx], self.df['second_party'][idx], self.df['facts'][idx]], dim =1), self.df['first_party_winner'][idx]\n",
    "    \n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "train_dataset = CourtDataset(train)\n",
    "val_dataset = CourtDataset(val)\n",
    "All_dataset = CourtDataset(df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "All_loader = DataLoader(All_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appended_df : target 분포 맞추기 위해 upsampling\n",
    "\n",
    "Downsampled_df : target 분포 맞추기 위해 downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_df = pd.concat([df, df[df['first_party_winner']==0]], axis = 0, ignore_index=True)\n",
    "appended_dataset = CourtDataset(appended_df)\n",
    "appended_loader = DataLoader(appended_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df = train_test_split(df[df['first_party_winner']==1], test_size = 0.6, random_state=42)[1]\n",
    "downsampled_df = pd.concat([downsampled_df, df[df['first_party_winner']==0]], axis = 0, ignore_index=True)\n",
    "downsampled_dataset = CourtDataset(downsampled_df)\n",
    "downsampled_loader = DataLoader(downsampled_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(608, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 2),)\n",
    "        \n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x, dim=1)\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.sequential(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6938352584838867\n",
      "Epoch: 1, Loss: 0.6911681294441223\n",
      "Epoch: 2, Loss: 0.525912880897522\n",
      "Epoch: 3, Loss: 0.4347936511039734\n",
      "Epoch: 4, Loss: 0.4163340628147125\n",
      "Epoch: 5, Loss: 0.3795323967933655\n",
      "Epoch: 6, Loss: 0.3823690414428711\n",
      "Epoch: 7, Loss: 0.37052929401397705\n",
      "Epoch: 8, Loss: 0.33081233501434326\n",
      "Epoch: 9, Loss: 0.38250818848609924\n",
      "Epoch: 10, Loss: 0.33986568450927734\n",
      "Epoch: 11, Loss: 0.3913154602050781\n",
      "Epoch: 12, Loss: 0.31966039538383484\n",
      "Epoch: 13, Loss: 0.3431662321090698\n",
      "Epoch: 14, Loss: 0.34105974435806274\n",
      "Epoch: 15, Loss: 0.34174856543540955\n",
      "Epoch: 16, Loss: 0.3152143061161041\n",
      "Epoch: 17, Loss: 0.31720635294914246\n",
      "Epoch: 18, Loss: 0.31538984179496765\n",
      "Epoch: 19, Loss: 0.32162103056907654\n",
      "Epoch: 20, Loss: 0.3671683073043823\n",
      "Epoch: 21, Loss: 0.3146723508834839\n",
      "Epoch: 22, Loss: 0.33544740080833435\n",
      "Epoch: 23, Loss: 0.343844473361969\n",
      "Epoch: 24, Loss: 0.31619492173194885\n",
      "Epoch: 25, Loss: 0.32839328050613403\n",
      "Epoch: 26, Loss: 0.31427133083343506\n",
      "Epoch: 27, Loss: 0.41846105456352234\n",
      "Epoch: 28, Loss: 0.31708019971847534\n",
      "Epoch: 29, Loss: 0.3471236526966095\n",
      "Epoch: 30, Loss: 0.3665381371974945\n",
      "Epoch: 31, Loss: 0.31410881876945496\n",
      "Epoch: 32, Loss: 0.34527918696403503\n",
      "Epoch: 33, Loss: 0.3300829231739044\n",
      "Epoch: 34, Loss: 0.3743823170661926\n",
      "Epoch: 35, Loss: 0.34504374861717224\n",
      "Epoch: 36, Loss: 0.35770824551582336\n",
      "Epoch: 37, Loss: 0.32284989953041077\n",
      "Epoch: 38, Loss: 0.31357038021087646\n",
      "Epoch: 39, Loss: 0.34598904848098755\n",
      "Epoch: 40, Loss: 0.31350836157798767\n",
      "Epoch: 41, Loss: 0.37152570486068726\n",
      "Epoch: 42, Loss: 0.31849873065948486\n",
      "Epoch: 43, Loss: 0.31334853172302246\n",
      "Epoch: 44, Loss: 0.31339696049690247\n",
      "Epoch: 45, Loss: 0.34613266587257385\n",
      "Epoch: 46, Loss: 0.31343427300453186\n",
      "Epoch: 47, Loss: 0.3133997917175293\n",
      "Epoch: 48, Loss: 0.3154458701610565\n",
      "Epoch: 49, Loss: 0.31334516406059265\n",
      "Epoch: 50, Loss: 0.3182732164859772\n",
      "Epoch: 51, Loss: 0.31943827867507935\n",
      "Epoch: 52, Loss: 0.31413885951042175\n",
      "Epoch: 53, Loss: 0.3133986294269562\n",
      "Epoch: 54, Loss: 0.375773161649704\n",
      "Epoch: 55, Loss: 0.3136025071144104\n",
      "Epoch: 56, Loss: 0.31407567858695984\n",
      "Epoch: 57, Loss: 0.3419695794582367\n",
      "Epoch: 58, Loss: 0.3426331579685211\n",
      "Epoch: 59, Loss: 0.34668105840682983\n",
      "Epoch: 60, Loss: 0.31441912055015564\n",
      "Epoch: 61, Loss: 0.31422147154808044\n",
      "Epoch: 62, Loss: 0.3146771192550659\n",
      "Epoch: 63, Loss: 0.31572696566581726\n",
      "Epoch: 64, Loss: 0.34060582518577576\n",
      "Epoch: 65, Loss: 0.34466591477394104\n",
      "Epoch: 66, Loss: 0.3135608732700348\n",
      "Epoch: 67, Loss: 0.3445560038089752\n",
      "Epoch: 68, Loss: 0.34451761841773987\n",
      "Epoch: 69, Loss: 0.3413718044757843\n",
      "Epoch: 70, Loss: 0.3399375081062317\n",
      "Epoch: 71, Loss: 0.32096433639526367\n",
      "Epoch: 72, Loss: 0.31394097208976746\n",
      "Epoch: 73, Loss: 0.3141995966434479\n",
      "Epoch: 74, Loss: 0.3641415238380432\n",
      "Epoch: 75, Loss: 0.3184250295162201\n",
      "Epoch: 76, Loss: 0.3441384732723236\n",
      "Epoch: 77, Loss: 0.3147580921649933\n",
      "Epoch: 78, Loss: 0.33534327149391174\n",
      "Epoch: 79, Loss: 0.31624916195869446\n",
      "Epoch: 80, Loss: 0.345539927482605\n",
      "Epoch: 81, Loss: 0.3133775591850281\n",
      "Epoch: 82, Loss: 0.3164825439453125\n",
      "Epoch: 83, Loss: 0.31384339928627014\n",
      "Epoch: 84, Loss: 0.31532222032546997\n",
      "Epoch: 85, Loss: 0.3469381630420685\n",
      "Epoch: 86, Loss: 0.32168954610824585\n",
      "Epoch: 87, Loss: 0.33965277671813965\n",
      "Epoch: 88, Loss: 0.3419951796531677\n",
      "Epoch: 89, Loss: 0.31378525495529175\n",
      "Epoch: 90, Loss: 0.31433773040771484\n",
      "Epoch: 91, Loss: 0.3132629692554474\n",
      "Epoch: 92, Loss: 0.34455588459968567\n",
      "Epoch: 93, Loss: 0.3132883310317993\n",
      "Epoch: 94, Loss: 0.3132622241973877\n",
      "Epoch: 95, Loss: 0.3157634437084198\n",
      "Epoch: 96, Loss: 0.3132626712322235\n",
      "Epoch: 97, Loss: 0.31328025460243225\n",
      "Epoch: 98, Loss: 0.31356507539749146\n",
      "Epoch: 99, Loss: 0.31326374411582947\n"
     ]
    }
   ],
   "source": [
    "def train(model, optim, train_loader, criterion, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for idx, (x, y) in enumerate(train_loader):\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            if idx % 100 == 0:\n",
    "                print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "    return model\n",
    "                \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertClassifier()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model = train(model, optimizer, downsampled_loader, criterion, device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.59677419354838%\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "    print('Accuracy: {}%'.format(100*correct/total))\n",
    "    \n",
    "test(model, val_loader, device)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(101), tensor(5096), tensor(19139), te...</td>\n",
       "      <td>[[tensor(101), tensor(2142), tensor(2163), ten...</td>\n",
       "      <td>[[tensor(101), tensor(1996), tensor(3118), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(101), tensor(23689), tensor(4059), te...</td>\n",
       "      <td>[[tensor(101), tensor(17244), tensor(8586), te...</td>\n",
       "      <td>[[tensor(101), tensor(17244), tensor(8586), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(101), tensor(2053), tensor(1012), ten...</td>\n",
       "      <td>[[tensor(101), tensor(4419), tensor(2547), ten...</td>\n",
       "      <td>[[tensor(101), tensor(1999), tensor(2526), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(101), tensor(7157), tensor(23699), te...</td>\n",
       "      <td>[[tensor(101), tensor(2142), tensor(2163), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2076), tensor(2010), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(101), tensor(16758), tensor(102), ten...</td>\n",
       "      <td>[[tensor(101), tensor(7658), tensor(7811), ten...</td>\n",
       "      <td>[[tensor(101), tensor(1999), tensor(2857), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>[[tensor(101), tensor(21404), tensor(6401), te...</td>\n",
       "      <td>[[tensor(101), tensor(3782), tensor(5096), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2429), tensor(2000), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>[[tensor(101), tensor(21311), tensor(102), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2137), tensor(4744), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2930), tensor(11518), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>[[tensor(101), tensor(8507), tensor(1037), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2520), tensor(1043), ten...</td>\n",
       "      <td>[[tensor(101), tensor(8507), tensor(24713), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>[[tensor(101), tensor(2899), tensor(2110), ten...</td>\n",
       "      <td>[[tensor(101), tensor(5690), tensor(102), tens...</td>\n",
       "      <td>[[tensor(101), tensor(1999), tensor(3285), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>[[tensor(101), tensor(10117), tensor(2358), te...</td>\n",
       "      <td>[[tensor(101), tensor(26026), tensor(7939), te...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2257), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            first_party  \\\n",
       "0     [[tensor(101), tensor(5096), tensor(19139), te...   \n",
       "1     [[tensor(101), tensor(23689), tensor(4059), te...   \n",
       "2     [[tensor(101), tensor(2053), tensor(1012), ten...   \n",
       "3     [[tensor(101), tensor(7157), tensor(23699), te...   \n",
       "4     [[tensor(101), tensor(16758), tensor(102), ten...   \n",
       "...                                                 ...   \n",
       "1235  [[tensor(101), tensor(21404), tensor(6401), te...   \n",
       "1236  [[tensor(101), tensor(21311), tensor(102), ten...   \n",
       "1237  [[tensor(101), tensor(8507), tensor(1037), ten...   \n",
       "1238  [[tensor(101), tensor(2899), tensor(2110), ten...   \n",
       "1239  [[tensor(101), tensor(10117), tensor(2358), te...   \n",
       "\n",
       "                                           second_party  \\\n",
       "0     [[tensor(101), tensor(2142), tensor(2163), ten...   \n",
       "1     [[tensor(101), tensor(17244), tensor(8586), te...   \n",
       "2     [[tensor(101), tensor(4419), tensor(2547), ten...   \n",
       "3     [[tensor(101), tensor(2142), tensor(2163), ten...   \n",
       "4     [[tensor(101), tensor(7658), tensor(7811), ten...   \n",
       "...                                                 ...   \n",
       "1235  [[tensor(101), tensor(3782), tensor(5096), ten...   \n",
       "1236  [[tensor(101), tensor(2137), tensor(4744), ten...   \n",
       "1237  [[tensor(101), tensor(2520), tensor(1043), ten...   \n",
       "1238  [[tensor(101), tensor(5690), tensor(102), tens...   \n",
       "1239  [[tensor(101), tensor(26026), tensor(7939), te...   \n",
       "\n",
       "                                                  facts  \n",
       "0     [[tensor(101), tensor(1996), tensor(3118), ten...  \n",
       "1     [[tensor(101), tensor(17244), tensor(8586), te...  \n",
       "2     [[tensor(101), tensor(1999), tensor(2526), ten...  \n",
       "3     [[tensor(101), tensor(2076), tensor(2010), ten...  \n",
       "4     [[tensor(101), tensor(1999), tensor(2857), ten...  \n",
       "...                                                 ...  \n",
       "1235  [[tensor(101), tensor(2429), tensor(2000), ten...  \n",
       "1236  [[tensor(101), tensor(2930), tensor(11518), te...  \n",
       "1237  [[tensor(101), tensor(8507), tensor(24713), te...  \n",
       "1238  [[tensor(101), tensor(1999), tensor(3285), ten...  \n",
       "1239  [[tensor(101), tensor(2006), tensor(2257), ten...  \n",
       "\n",
       "[1240 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.drop('ID',axis=1, inplace=True)\n",
    "\n",
    "test_df['facts'] = test_df['facts'].apply(lambda x: bert_tokenizer(x))\n",
    "test_df['first_party'] = test_df['first_party'].apply(lambda x: bert_tokenizer(x, party=True))\n",
    "test_df['second_party'] = test_df['second_party'].apply(lambda x: bert_tokenizer(x, party=True))\n",
    "\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CourtDataset(test_df, test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "predict_df = pd.DataFrame(columns=['ID', 'first_party_winner'])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, x in enumerate(test_loader):\n",
    "        x = x[0].to(device)\n",
    "        y_pred = model(x)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        predict_df.loc[idx] = ['TEST_{0:04}'.format(idx), predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>TEST_1235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>TEST_1236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>TEST_1237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>TEST_1238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>TEST_1239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  first_party_winner\n",
       "0     TEST_0000                   0\n",
       "1     TEST_0001                   1\n",
       "2     TEST_0002                   0\n",
       "3     TEST_0003                   1\n",
       "4     TEST_0004                   1\n",
       "...         ...                 ...\n",
       "1235  TEST_1235                   1\n",
       "1236  TEST_1236                   0\n",
       "1237  TEST_1237                   1\n",
       "1238  TEST_1238                   1\n",
       "1239  TEST_1239                   0\n",
       "\n",
       "[1240 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trials = 0\n",
    "while True:\n",
    "    if os.path.exists('submission/submission_{}.csv'.format(trials)):\n",
    "        trials += 1\n",
    "    else:\n",
    "        predict_df.to_csv('submission/submission_{}.csv'.format(trials), index=False)\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(101), tensor(6316), tensor(1037), ten...</td>\n",
       "      <td>[[tensor(101), tensor(11458), tensor(1037), te...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2238), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(101), tensor(4459), tensor(7343), ten...</td>\n",
       "      <td>[[tensor(101), tensor(5623), tensor(14824), te...</td>\n",
       "      <td>[[tensor(101), tensor(12716), tensor(5912), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(101), tensor(5006), tensor(3533), ten...</td>\n",
       "      <td>[[tensor(101), tensor(4116), tensor(12424), te...</td>\n",
       "      <td>[[tensor(101), tensor(2019), tensor(6041), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(101), tensor(4957), tensor(27901), te...</td>\n",
       "      <td>[[tensor(101), tensor(5232), tensor(102), tens...</td>\n",
       "      <td>[[tensor(101), tensor(5125), tensor(4957), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(101), tensor(2520), tensor(4656), ten...</td>\n",
       "      <td>[[tensor(101), tensor(6041), tensor(102), tens...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2258), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>[[tensor(101), tensor(9079), tensor(12792), te...</td>\n",
       "      <td>[[tensor(101), tensor(13918), tensor(20145), t...</td>\n",
       "      <td>[[tensor(101), tensor(3519), tensor(13266), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>[[tensor(101), tensor(26678), tensor(4916), te...</td>\n",
       "      <td>[[tensor(101), tensor(4707), tensor(5416), ten...</td>\n",
       "      <td>[[tensor(101), tensor(4707), tensor(5416), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>[[tensor(101), tensor(25039), tensor(13094), t...</td>\n",
       "      <td>[[tensor(101), tensor(2142), tensor(2163), ten...</td>\n",
       "      <td>[[tensor(101), tensor(1999), tensor(2826), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>[[tensor(101), tensor(7521), tensor(1998), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2358), tensor(1012), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2006), tensor(2233), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>[[tensor(101), tensor(2928), tensor(2386), ten...</td>\n",
       "      <td>[[tensor(101), tensor(2225), tensor(8584), ten...</td>\n",
       "      <td>[[tensor(101), tensor(7253), tensor(2928), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            first_party  \\\n",
       "0     [[tensor(101), tensor(6316), tensor(1037), ten...   \n",
       "1     [[tensor(101), tensor(4459), tensor(7343), ten...   \n",
       "2     [[tensor(101), tensor(5006), tensor(3533), ten...   \n",
       "3     [[tensor(101), tensor(4957), tensor(27901), te...   \n",
       "4     [[tensor(101), tensor(2520), tensor(4656), ten...   \n",
       "...                                                 ...   \n",
       "2473  [[tensor(101), tensor(9079), tensor(12792), te...   \n",
       "2474  [[tensor(101), tensor(26678), tensor(4916), te...   \n",
       "2475  [[tensor(101), tensor(25039), tensor(13094), t...   \n",
       "2476  [[tensor(101), tensor(7521), tensor(1998), ten...   \n",
       "2477  [[tensor(101), tensor(2928), tensor(2386), ten...   \n",
       "\n",
       "                                           second_party  \\\n",
       "0     [[tensor(101), tensor(11458), tensor(1037), te...   \n",
       "1     [[tensor(101), tensor(5623), tensor(14824), te...   \n",
       "2     [[tensor(101), tensor(4116), tensor(12424), te...   \n",
       "3     [[tensor(101), tensor(5232), tensor(102), tens...   \n",
       "4     [[tensor(101), tensor(6041), tensor(102), tens...   \n",
       "...                                                 ...   \n",
       "2473  [[tensor(101), tensor(13918), tensor(20145), t...   \n",
       "2474  [[tensor(101), tensor(4707), tensor(5416), ten...   \n",
       "2475  [[tensor(101), tensor(2142), tensor(2163), ten...   \n",
       "2476  [[tensor(101), tensor(2358), tensor(1012), ten...   \n",
       "2477  [[tensor(101), tensor(2225), tensor(8584), ten...   \n",
       "\n",
       "                                                  facts  \n",
       "0     [[tensor(101), tensor(2006), tensor(2238), ten...  \n",
       "1     [[tensor(101), tensor(12716), tensor(5912), te...  \n",
       "2     [[tensor(101), tensor(2019), tensor(6041), ten...  \n",
       "3     [[tensor(101), tensor(5125), tensor(4957), ten...  \n",
       "4     [[tensor(101), tensor(2006), tensor(2258), ten...  \n",
       "...                                                 ...  \n",
       "2473  [[tensor(101), tensor(3519), tensor(13266), te...  \n",
       "2474  [[tensor(101), tensor(4707), tensor(5416), ten...  \n",
       "2475  [[tensor(101), tensor(1999), tensor(2826), ten...  \n",
       "2476  [[tensor(101), tensor(2006), tensor(2233), ten...  \n",
       "2477  [[tensor(101), tensor(7253), tensor(2928), ten...  \n",
       "\n",
       "[2478 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_39660\\881510625.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tpot_df = tpot_df.append(tpot_df[tpot_df['target']==0], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>599</th>\n",
       "      <th>600</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>6316</td>\n",
       "      <td>1037</td>\n",
       "      <td>1012</td>\n",
       "      <td>2358</td>\n",
       "      <td>1012</td>\n",
       "      <td>25933</td>\n",
       "      <td>3372</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>4459</td>\n",
       "      <td>7343</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>5006</td>\n",
       "      <td>3533</td>\n",
       "      <td>23848</td>\n",
       "      <td>3702</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>4957</td>\n",
       "      <td>27901</td>\n",
       "      <td>2099</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>2520</td>\n",
       "      <td>4656</td>\n",
       "      <td>10882</td>\n",
       "      <td>9681</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>101</td>\n",
       "      <td>2430</td>\n",
       "      <td>23428</td>\n",
       "      <td>1005</td>\n",
       "      <td>11550</td>\n",
       "      <td>4636</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>101</td>\n",
       "      <td>2142</td>\n",
       "      <td>2163</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>101</td>\n",
       "      <td>25039</td>\n",
       "      <td>13094</td>\n",
       "      <td>2080</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>101</td>\n",
       "      <td>7521</td>\n",
       "      <td>1998</td>\n",
       "      <td>3019</td>\n",
       "      <td>3989</td>\n",
       "      <td>2326</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>101</td>\n",
       "      <td>2928</td>\n",
       "      <td>2386</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3307 rows × 609 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4     5      6     7    8  9  ...  599  \\\n",
       "0     101   6316   1037   1012   2358  1012  25933  3372  102  0  ...    0   \n",
       "1     101   4459   7343    102      0     0      0     0    0  0  ...    0   \n",
       "2     101   5006   3533  23848   3702   102      0     0    0  0  ...    0   \n",
       "3     101   4957  27901   2099    102     0      0     0    0  0  ...    0   \n",
       "4     101   2520   4656  10882   9681   102      0     0    0  0  ...    0   \n",
       "...   ...    ...    ...    ...    ...   ...    ...   ...  ... ..  ...  ...   \n",
       "3302  101   2430  23428   1005  11550  4636    102     0    0  0  ...    0   \n",
       "3303  101   2142   2163    102      0     0      0     0    0  0  ...    0   \n",
       "3304  101  25039  13094   2080    102     0      0     0    0  0  ...    0   \n",
       "3305  101   7521   1998   3019   3989  2326    102     0    0  0  ...    0   \n",
       "3306  101   2928   2386    102      0     0      0     0    0  0  ...    0   \n",
       "\n",
       "      600  601  602  603  604  605  606  607  target  \n",
       "0       0    0    0    0    0    0    0    0       1  \n",
       "1       0    0    0    0    0    0    0    0       0  \n",
       "2       0    0    0    0    0    0    0    0       1  \n",
       "3       0    0    0    0    0    0    0    0       0  \n",
       "4       0    0    0    0    0    0    0    0       1  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...     ...  \n",
       "3302    0    0    0    0    0    0    0    0       0  \n",
       "3303    0    0    0    0    0    0    0    0       0  \n",
       "3304    0    0    0    0    0    0    0    0       0  \n",
       "3305    0    0    0    0    0    0    0    0       0  \n",
       "3306    0    0    0    0    0    0    0    0       0  \n",
       "\n",
       "[3307 rows x 609 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list = []\n",
    "for i in range(len(df)):\n",
    "    x_list.append(torch.cat([df['first_party'][i], df['second_party'][i], df['facts'][i]], dim =1))\n",
    "\n",
    "for i in range(len(x_list)):\n",
    "    x_list[i] = x_list[i][0].tolist()\n",
    "    \n",
    "tpot_df = pd.DataFrame(x_list, columns = [i for i in range(608)])\n",
    "tpot_df['target'] = df['first_party_winner']\n",
    "\n",
    "#duplicate first_party_winner == 0\n",
    "\n",
    "tpot_df = tpot_df.append(tpot_df[tpot_df['target']==0], ignore_index=True)\n",
    "tpot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tpot_df['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>598</th>\n",
       "      <th>599</th>\n",
       "      <th>600</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>5096</td>\n",
       "      <td>19139</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>23689</td>\n",
       "      <td>4059</td>\n",
       "      <td>17889</td>\n",
       "      <td>2022</td>\n",
       "      <td>2869</td>\n",
       "      <td>16102</td>\n",
       "      <td>1044</td>\n",
       "      <td>9654</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2053</td>\n",
       "      <td>1012</td>\n",
       "      <td>5718</td>\n",
       "      <td>1011</td>\n",
       "      <td>5388</td>\n",
       "      <td>2475</td>\n",
       "      <td>2516</td>\n",
       "      <td>1024</td>\n",
       "      <td>2976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>7157</td>\n",
       "      <td>23699</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>16758</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>101</td>\n",
       "      <td>21404</td>\n",
       "      <td>6401</td>\n",
       "      <td>2473</td>\n",
       "      <td>1010</td>\n",
       "      <td>4297</td>\n",
       "      <td>1012</td>\n",
       "      <td>1010</td>\n",
       "      <td>3802</td>\n",
       "      <td>2632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>101</td>\n",
       "      <td>21311</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>101</td>\n",
       "      <td>8507</td>\n",
       "      <td>1037</td>\n",
       "      <td>1012</td>\n",
       "      <td>24713</td>\n",
       "      <td>1998</td>\n",
       "      <td>2198</td>\n",
       "      <td>1046</td>\n",
       "      <td>1012</td>\n",
       "      <td>5506</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>101</td>\n",
       "      <td>2899</td>\n",
       "      <td>2110</td>\n",
       "      <td>6207</td>\n",
       "      <td>6475</td>\n",
       "      <td>3222</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>101</td>\n",
       "      <td>10117</td>\n",
       "      <td>2358</td>\n",
       "      <td>7103</td>\n",
       "      <td>3363</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 608 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4     5      6     7     8     9    ...  \\\n",
       "0     101   5096  19139    102      0     0      0     0     0     0  ...   \n",
       "1     101  23689   4059  17889   2022  2869  16102  1044  9654  2015  ...   \n",
       "2     101   2053   1012   5718   1011  5388   2475  2516  1024  2976  ...   \n",
       "3     101   7157  23699    102      0     0      0     0     0     0  ...   \n",
       "4     101  16758    102      0      0     0      0     0     0     0  ...   \n",
       "...   ...    ...    ...    ...    ...   ...    ...   ...   ...   ...  ...   \n",
       "1235  101  21404   6401   2473   1010  4297   1012  1010  3802  2632  ...   \n",
       "1236  101  21311    102      0      0     0      0     0     0     0  ...   \n",
       "1237  101   8507   1037   1012  24713  1998   2198  1046  1012  5506  ...   \n",
       "1238  101   2899   2110   6207   6475  3222    102     0     0     0  ...   \n",
       "1239  101  10117   2358   7103   3363   102      0     0     0     0  ...   \n",
       "\n",
       "      598  599  600  601  602  603  604  605  606  607  \n",
       "0       0    0    0    0    0    0    0    0    0    0  \n",
       "1       0    0    0    0    0    0    0    0    0    0  \n",
       "2       0    0    0    0    0    0    0    0    0    0  \n",
       "3       0    0    0    0    0    0    0    0    0    0  \n",
       "4       0    0    0    0    0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1235    0    0    0    0    0    0    0    0    0    0  \n",
       "1236    0    0    0    0    0    0    0    0    0    0  \n",
       "1237    0    0    0    0    0    0    0    0    0    0  \n",
       "1238    0    0    0    0    0    0    0    0    0    0  \n",
       "1239    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[1240 rows x 608 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_list = []\n",
    "for i in range(len(test_df)):\n",
    "    test_x_list.append(torch.cat([test_df['first_party'][i], test_df['second_party'][i], test_df['facts'][i]], dim =1))\n",
    "\n",
    "for i in range(len(test_x_list)):\n",
    "    test_x_list[i] = test_x_list[i][0].tolist()\n",
    "    \n",
    "    \n",
    "test_tpot_df = pd.DataFrame(test_x_list, columns = [i for i in range(608)])\n",
    "test_tpot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.7 of tpot is outdated. Version 0.12.0 was released Thursday May 25, 2023.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fbac1ac69042a09019fcafc5e85671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9026326494234225\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9114003775292403\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9114003775292403\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9114003775292403\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9516223245014649\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(PCA(input_matrix, iterated_power=7, svd_solver=randomized), bootstrap=True, criterion=gini, max_features=0.9000000000000001, min_samples_leaf=1, min_samples_split=16, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tpot_df.iloc[:,:608]\n",
    "y = tpot_df.iloc[:,608]\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "tpot.fit(X, y)\n",
    "\n",
    "y_pred = tpot.predict(test_tpot_df)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "#save model\n",
    "with open('tpot_model.pkl', 'wb') as f:\n",
    "    pickle.dump(tpot.fitted_pipeline_, f)\n",
    "    \n",
    "X_test = test_tpot_df\n",
    "\n",
    "y_test_pred = tpot.predict(X_test)\n",
    "\n",
    "predict_df = pd.DataFrame(columns=['ID', 'first_party_winner'])\n",
    "\n",
    "for idx in range(len(y_test_pred)):\n",
    "    predict_df.loc[idx] = ['TEST_{0:04}'.format(idx), y_test_pred[idx]]\n",
    "    \n",
    "\n",
    "trials = 0\n",
    "while True:\n",
    "    if os.path.exists('submission/submission_{}.csv'.format(trials)):\n",
    "        trials += 1\n",
    "    else:\n",
    "        predict_df.to_csv('submission/submission_{}.csv'.format(trials), index=False)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
